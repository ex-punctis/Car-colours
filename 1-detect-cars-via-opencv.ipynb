{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve image paths in given directories and save them to file\n",
    "\n",
    "###########################\n",
    "###### CONFIGURATION ######\n",
    "img_dirs = ['~/Desktop/161_1025', '~/Desktop/163_1027'] # list of directories with images\n",
    "img_exts = ['.jpg', '.JPG']       # valid image extensions\n",
    "imagelist_file = 'imagelist.txt'  # file with image paths\n",
    "###########################\n",
    "\n",
    "import os\n",
    "\n",
    "def img_path_gen():\n",
    "    for dir in img_dirs:\n",
    "        for item in os.listdir(os.path.expanduser(dir)):\n",
    "            path2item = os.path.join(os.path.expanduser(dir), item)\n",
    "            if os.path.isfile(path2item):\n",
    "                if os.path.splitext(path2item)[-1] in img_exts:\n",
    "                    yield path2item\n",
    "\n",
    "with open(os.path.expanduser(imagelist_file), 'w') as file:                  \n",
    "    for img_path in img_path_gen():\n",
    "        print(img_path, file=file)\n",
    "\n",
    "print('Image paths saved to', os.path.expanduser(imagelist_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# YOLOv3 in openCV\n",
    "\n",
    "# Based on\n",
    "# https://github.com/arunponnusamy/object-detection-opencv \n",
    "# by Arun Ponnusamy (http://www.arunponnusamy.com)\n",
    "\n",
    "###########################\n",
    "###### CONFIGURATION ######\n",
    "\n",
    "# jupyter matplotlib configs:\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# YOLOv3 files from https://github.com/pjreddie/darknet\n",
    "imagelist_file = 'imagelist.txt' # file with image paths\n",
    "classes_file = '~/git/darknet/data/coco.names' # coco class labels\n",
    "model_file = '~/git/darknet/cfg/yolov3.cfg'    # model definition\n",
    "weights_file = '~/git/darknet/yolov3.weights'  # model weights (coco)\n",
    "\n",
    "show_images = False # show images with detected objects\n",
    "\n",
    "resolution = 960    # default reslution 416\n",
    "###########################\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_output_layers(net):\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    return output_layers\n",
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "    label = str(classes[class_id])\n",
    "    color = COLORS[class_id]\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 10)\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 3, color, 5)\n",
    "\n",
    "\n",
    "imagelist_file = os.path.expanduser(imagelist_file)\n",
    "classes_file = os.path.expanduser(classes_file)\n",
    "model_file = os.path.expanduser(model_file)\n",
    "weights_file = os.path.expanduser(weights_file)\n",
    "\n",
    "detected_objects = {}\n",
    "counter = 0\n",
    "    \n",
    "with open(imagelist_file, 'r') as source:\n",
    "    for img_path in source.readlines():\n",
    "        counter += 1\n",
    "        print ('\\r', counter, ': ', img_path.strip(), end='')\n",
    "        detected_objects[img_path.strip()] = []\n",
    "        \n",
    "        image = cv2.imread(img_path.strip())\n",
    "\n",
    "        Height, Width = image.shape[0:2]\n",
    "        scale = 1/255\n",
    "\n",
    "        classes = None\n",
    "\n",
    "        with open(classes_file, 'r') as f:\n",
    "            classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        COLORS = np.random.uniform(100, 230, size=(len(classes), 3))\n",
    "\n",
    "        net = cv2.dnn.readNet(weights_file, model_file)\n",
    "        blob = cv2.dnn.blobFromImage(image, scale, (resolution,resolution), (0,0,0), True, crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        outs = net.forward(get_output_layers(net))\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        conf_threshold = 0.6\n",
    "        nms_threshold = 0.4\n",
    "\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * Width)\n",
    "                    center_y = int(detection[1] * Height)\n",
    "                    w = int(detection[2] * Width)\n",
    "                    h = int(detection[3] * Height)\n",
    "                    x = center_x - w / 2\n",
    "                    y = center_y - h / 2\n",
    "                    class_ids.append(class_id)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([x, y, w, h])\n",
    "\n",
    "        for i in cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold):\n",
    "            i = i[0]\n",
    "            box = boxes[i]\n",
    "            x0, y0, w, h = [round(i) for i in box]\n",
    "            x0 = max(0, x0)\n",
    "            y0 = max(0, y0)\n",
    "            x1 = min(Width, x0 + w)\n",
    "            y1 = min(Height, y0 + h)\n",
    "            \n",
    "            #print('{:15} {:.2f}, {:4}, {:4}, {:4}, {:4}'.format(classes[class_ids[i]], confidences[i], x, y, w, h)) \n",
    "            \n",
    "            detected_objects[img_path.strip()].append({'object':classes[class_ids[i]], \n",
    "                                                       'confidence':'%.2f' % confidences[i],\n",
    "                                                       'x0': x0, 'y0': y0, 'x1': x1, 'y1': y1})\n",
    "            if show_images: draw_prediction(image, class_ids[i], confidences[i], x, y, x+w, y+h)\n",
    "\n",
    "        if show_images:\n",
    "            plt.figure(figsize=(12,9))\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.show()\n",
    "            \n",
    "print('\\nObject detection completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save car coordinates to a file\n",
    "\n",
    "###########################\n",
    "###### CONFIGURATION ######\n",
    "\n",
    "detected_objs_file = 'detected_objects.txt'\n",
    "\n",
    "###########################\n",
    "\n",
    "\n",
    "with open(os.path.expanduser(detected_objs_file), 'w') as file:                  \n",
    "    json.dump(detected_objects, file)\n",
    "    print ('Detections saved to', detected_objs_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.7.1",
   "language": "python",
   "name": "python-3.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
